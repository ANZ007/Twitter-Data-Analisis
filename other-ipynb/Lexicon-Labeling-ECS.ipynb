{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd6a95b9-4c06-4ecd-9ceb-61409a157d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ede80e-e3ad-4377-9102-6022a6eaa9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/tweets_ecs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc1b05c-d93e-4e32-8f14-300b498b58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_detokenize = []\n",
    "\n",
    "def detokenize(text):\n",
    "    text1 = text.replace(']','').replace('[','')\n",
    "    arr = text1.replace('\"','').replace(\"\\'\",\"\").split(\",\")\n",
    "    return(TreebankWordDetokenizer().detokenize(arr))\n",
    "\n",
    "df['tweet'] = df['tweet'].astype('U').apply(detokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433e0f33-61b1-4c22-96a2-9ce2db7ecf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kata unik pada Dataset : 6013\n"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "for i in range(0,len(df['tweet'])):\n",
    "    sentence = df['tweet'][i]\n",
    "    word_token = word_tokenize(sentence)\n",
    "    for j in word_token:\n",
    "        if j not in word_dict:\n",
    "            word_dict[j] = 1\n",
    "        else:\n",
    "            word_dict[j] += 1\n",
    "            \n",
    "print(\"Kata unik pada Dataset : \"+str(len(word_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcfba1b7-a3df-4c9b-816a-0b9767471b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamus pada corpus (lexicon) : 11930\n"
     ]
    }
   ],
   "source": [
    "lexicon = pd.read_csv('data/lexicon/full_lexicon.csv')\n",
    "lexicon = lexicon.drop(lexicon[(lexicon['word'] == 'bukan')|(lexicon['word'] == 'tidak')|(lexicon['word'] == 'ga')|(lexicon['word'] == 'gk') ].index,axis=0)\n",
    "lexicon = lexicon.reset_index(drop=True)\n",
    "len(lexicon)\n",
    "print(\"Kamus pada corpus (lexicon) : \"+str(len(lexicon)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663b85d8-6c1c-4485-9b74-a8ecc92d2a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah setiap kata pada corpus :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    11190\n",
       "2      684\n",
       "3       26\n",
       "4       25\n",
       "5        5\n",
       "Name: number_of_words, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_word = lexicon['word'].to_list()\n",
    "lexicon_num_words = lexicon['number_of_words']\n",
    "print(\"Jumlah setiap kata pada corpus :\")\n",
    "lexicon['number_of_words'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "856844da-44ef-4776-b97c-8ea3dd84babf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e6fe7ad6614698ab8fceb2b895f6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/6013 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4618"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns_words = []\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "for word in tqdm(word_dict.keys(),desc='Progress'):\n",
    "    if word not in lexicon_word:\n",
    "        kata_dasar = stemmer.stem(word)\n",
    "        if kata_dasar not in lexicon_word:\n",
    "            ns_words.append(word)\n",
    "len(ns_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacc91d4-41eb-4572-a169-d6f5db8fc1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "telur 2955\n",
      "ternak 1019\n",
      "telor 646\n",
      "jagung 367\n",
      "pakan 337\n",
      "rp 240\n",
      "kg 229\n",
      "pasar 198\n",
      "order 170\n",
      "pempek 169\n",
      "lenjer 167\n",
      "rm 154\n",
      "dm 145\n",
      "ribu 141\n",
      "blitar 141\n",
      "kilo 107\n",
      "kulit 103\n",
      "pakai 103\n",
      "palembang 100\n",
      "tan 97\n"
     ]
    }
   ],
   "source": [
    "ns_words_list = {k:v for (k,v) in word_dict.items() if ((k in ns_words)&(v>3))}\n",
    "sort_orders = sorted(ns_words_list.items(), key=lambda x: x[1], reverse=True)\n",
    "sort_orders=sort_orders[0:20]\n",
    "for i in sort_orders:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70603186-426d-48c1-91d4-405a6d9f40bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbb2a953ae642d5a875898f2f399359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/2879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2879"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negasi = ['bukan','tidak','ga','gk']\n",
    "sencol =[]\n",
    "senrow =np.array([])\n",
    "nsen = 0\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "sentiment_list = []\n",
    "# function to write the word's sentiment if it is founded\n",
    "def found_word(ind,words,word,sen,sencol,sentiment,add):\n",
    "    # if it is already included in the bag of words matrix, then just increase the value\n",
    "    if word in sencol:\n",
    "        sen[sencol.index(word)] += 1\n",
    "    else:\n",
    "    #if not, than add new word\n",
    "        sencol.append(word)\n",
    "        sen.append(1)\n",
    "        add += 1\n",
    "    #if there is a negation word before it, the sentiment would be the negation of it's sentiment\n",
    "    if (words[ind-1] in negasi):\n",
    "        sentiment += -lexicon['weight'][lexicon_word.index(word)]\n",
    "    else:\n",
    "        sentiment += lexicon['weight'][lexicon_word.index(word)]\n",
    "    \n",
    "    return sen,sencol,sentiment,add\n",
    "            \n",
    "# checking every words, if they are appear in the lexicon, and then calculate their sentiment if they do\n",
    "for i in tqdm(range(len(df)),desc='Progress'):\n",
    "    nsen = senrow.shape[0]\n",
    "    words = word_tokenize(df['tweet'][i])\n",
    "    sentiment = 0 \n",
    "    add = 0\n",
    "    prev = [0 for ii in range(len(words))]\n",
    "    n_words = len(words)\n",
    "    if len(sencol)>0:\n",
    "        sen =[0 for j in range(len(sencol))]\n",
    "    else:\n",
    "        sen =[]\n",
    "    \n",
    "    for word in words:\n",
    "        ind = words.index(word)\n",
    "        # check whether they are included in the lexicon\n",
    "        if word in lexicon_word :\n",
    "            sen,sencol,sentiment,add= found_word(ind,words,word,sen,sencol,sentiment,add)\n",
    "        else:\n",
    "        # if not, then check the root word\n",
    "            kata_dasar = stemmer.stem(word)\n",
    "            if kata_dasar in lexicon_word:\n",
    "                sen,sencol,sentiment,add= found_word(ind,words,kata_dasar,sen,sencol,sentiment,add)\n",
    "        # if still negative, try to match the combination of words with the adjacent words\n",
    "            elif(n_words>1):\n",
    "                if ind-1>-1:\n",
    "                    back_1    = words[ind-1]+' '+word\n",
    "                    if (back_1 in lexicon_word):\n",
    "                        sen,sencol,sentiment,add= found_word(ind,words,back_1,sen,sencol,sentiment,add)\n",
    "                    elif(ind-2>-1):\n",
    "                        back_2    = words[ind-2]+' '+back_1\n",
    "                        if back_2 in lexicon_word:\n",
    "                            sen,sencol,sentiment,add= found_word(ind,words,back_2,sen,sencol,sentiment,add)\n",
    "    # if there is new word founded, then expand the matrix\n",
    "    if add>0:  \n",
    "        if i>0:\n",
    "            if (nsen==0):\n",
    "                senrow = np.zeros([i,add],dtype=int)\n",
    "            elif(i!=nsen):\n",
    "                padding_h = np.zeros([nsen,add],dtype=int)\n",
    "                senrow = np.hstack((senrow,padding_h))\n",
    "                padding_v = np.zeros([(i-nsen),senrow.shape[1]],dtype=int)\n",
    "                senrow = np.vstack((senrow,padding_v))\n",
    "            else:\n",
    "                padding =np.zeros([nsen,add],dtype=int)\n",
    "                senrow = np.hstack((senrow,padding))\n",
    "            senrow = np.vstack((senrow,sen))\n",
    "        if i==0:\n",
    "            senrow = np.array(sen).reshape(1,len(sen))\n",
    "    # if there isn't then just update the old matrix\n",
    "    elif(nsen>0):\n",
    "        senrow = np.vstack((senrow,sen))\n",
    "        \n",
    "    sentiment_list.append(sentiment)\n",
    "    \n",
    "len(sentiment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e5854ae-0ff1-4e52-9115-8916ceeed02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ayam</th>\n",
       "      <th>diri</th>\n",
       "      <th>atas</th>\n",
       "      <th>sendiri</th>\n",
       "      <th>stabil</th>\n",
       "      <th>harga</th>\n",
       "      <th>sebab</th>\n",
       "      <th>anjlok</th>\n",
       "      <th>kaget</th>\n",
       "      <th>turun</th>\n",
       "      <th>...</th>\n",
       "      <th>mood</th>\n",
       "      <th>konyol</th>\n",
       "      <th>riil</th>\n",
       "      <th>mampir</th>\n",
       "      <th>lagak</th>\n",
       "      <th>hero</th>\n",
       "      <th>tembak</th>\n",
       "      <th>sendal</th>\n",
       "      <th>sembahyang</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2879 rows × 1350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ayam  diri  atas  sendiri  stabil  harga  sebab  anjlok  kaget  turun  \\\n",
       "0        1     0     0        0       0      0      0       0      0      0   \n",
       "1        0     1     1        1       1      1      0       0      0      0   \n",
       "2        0     0     0        0       0      1      1       1      1      0   \n",
       "3        3     0     0        0       0      1      0       1      0      1   \n",
       "4        3     0     0        0       0      2      1       0      0      1   \n",
       "...    ...   ...   ...      ...     ...    ...    ...     ...    ...    ...   \n",
       "2874     1     0     0        0       0      1      0       1      0      0   \n",
       "2875     0     0     0        0       0      1      0       0      0      0   \n",
       "2876     0     0     0        0       0      1      0       0      0      0   \n",
       "2877     0     0     0        0       0      1      0       1      0      0   \n",
       "2878     1     0     0        0       0      1      0       1      0      0   \n",
       "\n",
       "      ...  mood  konyol  riil  mampir  lagak  hero  tembak  sendal  \\\n",
       "0     ...     0       0     0       0      0     0       0       0   \n",
       "1     ...     0       0     0       0      0     0       0       0   \n",
       "2     ...     0       0     0       0      0     0       0       0   \n",
       "3     ...     0       0     0       0      0     0       0       0   \n",
       "4     ...     0       0     0       0      0     0       0       0   \n",
       "...   ...   ...     ...   ...     ...    ...   ...     ...     ...   \n",
       "2874  ...     0       0     0       0      0     0       0       0   \n",
       "2875  ...     0       0     0       0      0     0       0       1   \n",
       "2876  ...     0       0     0       0      0     0       0       0   \n",
       "2877  ...     0       0     0       0      0     0       0       0   \n",
       "2878  ...     0       0     0       0      0     0       0       0   \n",
       "\n",
       "      sembahyang  sentiment  \n",
       "0              0         -2  \n",
       "1              0         -2  \n",
       "2              0          5  \n",
       "3              0         -1  \n",
       "4              0          4  \n",
       "...          ...        ...  \n",
       "2874           0         -7  \n",
       "2875           0          9  \n",
       "2876           1         23  \n",
       "2877           0         -5  \n",
       "2878           0         -7  \n",
       "\n",
       "[2879 rows x 1350 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sencol.append('sentiment')\n",
    "sentiment_array = np.array(sentiment_list).reshape(senrow.shape[0],1)\n",
    "sentiment_data = np.hstack((senrow,sentiment_array))\n",
    "\n",
    "df_sen = pd.DataFrame(sentiment_data,columns = sencol)\n",
    "df_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a524f5-7a23-4284-9d3e-25723bbacc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>polaritas</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jbharga  ayam  rm  tgk  telor  wyam  papan  rm...</td>\n",
       "      <td>-2</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diri  di  atas  kaki  sendiri  serap  telur  t...</td>\n",
       "      <td>-2</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sebab  harga  telur  anjlok  versi  dagang  kaget</td>\n",
       "      <td>5</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turun  minta  masyarakat  telur  ayam  ppkm  l...</td>\n",
       "      <td>-1</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ternak  ayam  telur  menga  rugi  ratus  juta ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>blitar  harga  telur  ayam  anjlok  ternak  an...</td>\n",
       "      <td>-7</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>titip  sendal  baca  artikel  nasi  goreng  go...</td>\n",
       "      <td>9</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>suka  mooncake  isi  telur  daerah  mahal  mah...</td>\n",
       "      <td>23</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>harga  telur  anjlok  ternak  jateng  babak  b...</td>\n",
       "      <td>-5</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>harga  telur  ayam  anjlok  ternak  ancam  gul...</td>\n",
       "      <td>-7</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2879 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  polaritas sentimen\n",
       "0     jbharga  ayam  rm  tgk  telor  wyam  papan  rm...         -2  Negatif\n",
       "1     diri  di  atas  kaki  sendiri  serap  telur  t...         -2  Negatif\n",
       "2     sebab  harga  telur  anjlok  versi  dagang  kaget          5  Positif\n",
       "3     turun  minta  masyarakat  telur  ayam  ppkm  l...         -1  Negatif\n",
       "4     ternak  ayam  telur  menga  rugi  ratus  juta ...          4  Positif\n",
       "...                                                 ...        ...      ...\n",
       "2874  blitar  harga  telur  ayam  anjlok  ternak  an...         -7  Negatif\n",
       "2875  titip  sendal  baca  artikel  nasi  goreng  go...          9  Positif\n",
       "2876  suka  mooncake  isi  telur  daerah  mahal  mah...         23  Positif\n",
       "2877  harga  telur  anjlok  ternak  jateng  babak  b...         -5  Negatif\n",
       "2878  harga  telur  ayam  anjlok  ternak  ancam  gul...         -7  Negatif\n",
       "\n",
       "[2879 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melihat sentimen dari tweet original\n",
    "\n",
    "cek_df = pd.DataFrame()\n",
    "temp_cek_df = []\n",
    "\n",
    "cek_df['tweet'] = df['tweet'].copy()\n",
    "cek_df['polaritas']  = df_sen['sentiment'].copy()\n",
    "\n",
    "for senti in df_sen['sentiment']:\n",
    "    if (int(senti) >= 0):\n",
    "        label = \"Positif\"\n",
    "    # elif (int(senti) == 0):\n",
    "    #     label = \"Netral\"    \n",
    "    else:\n",
    "        label = \"Negatif\"\n",
    "    temp_cek_df.append([label])\n",
    "    \n",
    "temp_cek_df = pd.DataFrame(temp_cek_df, columns=['sentimen'])\n",
    "cek_df['sentimen'] = temp_cek_df['sentimen'].copy()\n",
    "cek_df.reset_index(drop=True, inplace=True)\n",
    "cek_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efb914d5-203a-446e-9376-3475e46f9bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positif : 2207  tweet\n",
      "Negatif : 672  tweet\n"
     ]
    }
   ],
   "source": [
    "print(\"Positif :\",len(cek_df[cek_df.polaritas>=0]), \" tweet\")\n",
    "print(\"Negatif :\",len(cek_df[cek_df.polaritas<0]), \" tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ec25293-ed51-4fd8-9d7c-6d9c065c9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cek_df.to_csv(\"data/tweets_labelled_ecs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7141bb0f-3473-4528-8c86-b587908e5bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/anz007/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "cek_df['tweet'] = cek_df['tweet'].apply(word_tokenize_wrapper)\n",
    "cek_df.to_csv(\"data/tweets_labelled_tokenized_ecs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4736ce49-229b-4304-821f-82142bcfc767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
