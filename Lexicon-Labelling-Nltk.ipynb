{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c08e86-31fb-47d2-ad7f-2792957fbc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import json\n",
    "import reprlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75886174-619c-42f9-9657-e3287215f7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ANZ007\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55d9a59f-357f-4d3e-b82d-5b1e09c1536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/tweets_sastrawi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab566dc-f725-44e8-9a7d-5ffd3ffaa0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_detokenize = []\n",
    "\n",
    "def detokenize(text):\n",
    "    text1 = text.replace(']','').replace('[','')\n",
    "    arr = text1.replace('\"','').replace(\"\\'\",\"\").split(\",\")\n",
    "    return(TreebankWordDetokenizer().detokenize(arr))\n",
    "\n",
    "df['tweet'] = df['tweet'].astype('U').apply(detokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7c7926-aa89-498d-9404-852d58ce28e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'(barang) bekas': -4, '(olahraga) bokser': -5, '(tua) uzur': -3, 'Anda': -4, ...}\n",
      "{'(hujan) gerimis': 1, '(warna) dadu': 3, 'Ahad': 3, 'Sri paduka': 4, ...}\n"
     ]
    }
   ],
   "source": [
    "# Memanfaatkan nltk VADER untuk menggunakan leksikon kustom\n",
    "sia1A, sia1B, sia2 = SentimentIntensityAnalyzer(), SentimentIntensityAnalyzer(), SentimentIntensityAnalyzer()\n",
    "# membersihkan leksikon VADER default\n",
    "sia1A.lexicon.clear()\n",
    "sia1B.lexicon.clear()\n",
    "sia2.lexicon.clear()\n",
    "\n",
    "# Membaca leksikon InSet\n",
    "# Leksikon InSet lexicon dibagi menjadi dua, yakni polaritas negatif dan polaritas positif;\n",
    "# kita akan menggunakan nilai compound saja untuk memberi label pada suatu kalimat\n",
    "with open('data/lexicon/InSet/negative.json') as f:\n",
    "    data1A = f.read()\n",
    "with open('data/lexicon/InSet/positive.json') as f:\n",
    "    data1B = f.read()\n",
    "\n",
    "# Membaca leksikon kata2 kasar\n",
    "with open('data/lexicon/swear-words.json') as f:\n",
    "    data2 = f.read()\n",
    "\n",
    "# Mengubah leksikon sebagai dictionary\n",
    "insetNeg = json.loads(data1A)\n",
    "insetPos = json.loads(data1B)\n",
    "# senti = json.loads(data2)\n",
    "\n",
    "# Update leksikon VADER yang sudah 'dimodifikasi'\n",
    "sia1A.lexicon.update(insetNeg)\n",
    "sia1B.lexicon.update(insetPos)\n",
    "# sia2.lexicon.update(senti)\n",
    "\n",
    "print(reprlib.repr(sia1A.lexicon))\n",
    "print(reprlib.repr(sia1B.lexicon))\n",
    "# print(reprlib.repr(sia2.lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c197e0-77ca-4a9a-8284-bac1158c0d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insetNeg:  {'neg': 0.526, 'neu': 0.474, 'pos': 0.0, 'compound': -0.875}\n",
      "insetPos:  {'neg': 0.0, 'neu': 0.333, 'pos': 0.667, 'compound': 0.9517}\n",
      "insetCpdSum: 'compound': 0.07669999999999999\n",
      "senti\t:  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "sample = \"kalau kamu sudah sampai sini kamu hebat ayo terus kamu pasti bisa\"\n",
    "print(\"insetNeg: \", sia1A.polarity_scores(sample))\n",
    "print(\"insetPos: \", sia1B.polarity_scores(sample))\n",
    "print(\"insetCpdSum: 'compound':\", sia1A.polarity_scores(sample)[\"compound\"] + sia1B.polarity_scores(sample)[\"compound\"])\n",
    "\n",
    "print(\"senti\\t: \", sia2.polarity_scores(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76b5832-e02b-438a-b3d2-f297c513319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_positive_inset(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia1A.polarity_scores(tweet)[\"compound\"] + sia1B.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "# def is_positive_senti(tweet: str) -> bool:\n",
    "#     \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "#     return sia2.polarity_scores(tweet)[\"compound\"] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "617f9218-6740-40c4-a231-2ab13fc63b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jbharga  ayam  rm  tgk  telor  wyam  papan  rm...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diri  di  atas  kaki  sendiri  serap  telur  t...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sebab  harga  telur  anjlok  versi  dagang  kaget</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turun  minta  masyarakat  telur  ayam  ppkm  l...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ternak  ayam  telur  aku  rugi  ratus  juta  r...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>blitar  harga  telur  ayam  anjlok  ternak  an...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>titip  sendal  baca  artikel  nasi  goreng  go...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>suka  mooncake  isi  telur  daerah  mahal  mah...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>harga  telur  anjlok  ternak  jateng  babak  bur</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>harga  telur  ayam  anjlok  ternak  ancam  gul...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2879 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet sentimen\n",
       "0     jbharga  ayam  rm  tgk  telor  wyam  papan  rm...  Negatif\n",
       "1     diri  di  atas  kaki  sendiri  serap  telur  t...  Negatif\n",
       "2     sebab  harga  telur  anjlok  versi  dagang  kaget  Negatif\n",
       "3     turun  minta  masyarakat  telur  ayam  ppkm  l...  Negatif\n",
       "4     ternak  ayam  telur  aku  rugi  ratus  juta  r...  Positif\n",
       "...                                                 ...      ...\n",
       "2874  blitar  harga  telur  ayam  anjlok  ternak  an...  Negatif\n",
       "2875  titip  sendal  baca  artikel  nasi  goreng  go...  Negatif\n",
       "2876  suka  mooncake  isi  telur  daerah  mahal  mah...  Positif\n",
       "2877   harga  telur  anjlok  ternak  jateng  babak  bur  Negatif\n",
       "2878  harga  telur  ayam  anjlok  ternak  ancam  gul...  Negatif\n",
       "\n",
       "[2879 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "temp_df2 = []\n",
    "\n",
    "df2['tweet'] = df['tweet'].copy()\n",
    "\n",
    "for tweet in df2['tweet']:\n",
    "    if is_positive_inset(tweet) == True:\n",
    "        label = \"Positif\"\n",
    "    else:\n",
    "        label = \"Negatif\"\n",
    "    temp_df2.append([label])\n",
    "    \n",
    "temp_df2 = pd.DataFrame(temp_df2, columns=['sentimen'])\n",
    "df2['sentimen'] = temp_df2['sentimen'].copy()\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a35e7bfa-b1bc-47ce-b287-1c79f33acbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positif : 1649  tweet\n",
      "Negatif : 1230  tweet\n"
     ]
    }
   ],
   "source": [
    "print(\"Positif :\",len(df2[df2.sentimen==\"Positif\"]), \" tweet\")\n",
    "print(\"Negatif :\",len(df2[df2.sentimen==\"Negatif\"]), \" tweet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
