{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abbe8ce7-0156-4126-bcec-167b08a4854c",
   "metadata": {},
   "source": [
    "# Pelabelan Data Menggunakan Pretrained Model\n",
    "Menggunakan Transformer dengan Model Indonesian RoBERTa Base Sentiment Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafbb06-0f46-407d-b146-3cf49a6bc948",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f57409-d8d6-4461-8388-fdb4e3712c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca927c0-f90f-48aa-b5af-44a294aaaffe",
   "metadata": {},
   "source": [
    "## Import Data dari Proses Sebelumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e9cf2b-8c40-4836-a5e8-d45a634e192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/tweets_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d046d2-89e4-4fc3-a1c6-d55c8261c189",
   "metadata": {},
   "source": [
    "## Mempersiapkan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f61fac-39d7-4981-bb76-789bfa776076",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_name = \"w11wo/indonesian-roberta-base-sentiment-classifier\"\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=pretrained_name,\n",
    "    tokenizer=pretrained_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb50c5-a718-48f7-95bd-236111668feb",
   "metadata": {},
   "source": [
    "## Polarity Scoring and Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fcf103-0735-4b55-92f3-9dc8c2b034d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns = ['tweet', 'sentimen', 'skor'])\n",
    "for i in tqdm(df['tweet'],desc='Scoring and Labelling..'):\n",
    "    sentiment = nlp(i)[0]['label']\n",
    "    score = nlp(i)[0]['score']\n",
    "    df2 = pd.concat([df2, pd.DataFrame([{\"tweet\" : i, \"sentimen\" : sentiment, \"skor\" : score}])])\n",
    "    \n",
    "def change_languange(text):\n",
    "    if text == \"neutral\":\n",
    "        return \"Netral\"\n",
    "    if text == \"positive\":\n",
    "        return \"Positif\"\n",
    "    if text == \"negative\":\n",
    "        return \"Negatif\"\n",
    "\n",
    "df2['sentimen'] = df2['sentimen'].apply(change_languange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee5cdf-6903-4eb2-8c3d-8499e319b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d38a51-d38a-4f88-a889-82ff6116349d",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ace1a6-b111-4192-997d-c8d6bb45c940",
   "metadata": {},
   "source": [
    "### Total tweet positif, negatif, atau netral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8426059-5867-493c-84a8-94043cd0432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Positif :\",len(df2[df2.sentimen==\"Positif\"]), \" tweet\")\n",
    "print(\"Netral :\",len(df2[df2.sentimen==\"Netral\"]), \" tweet\")\n",
    "print(\"Negatif :\",len(df2[df2.sentimen==\"Negatif\"]), \" tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef2d8c3-969c-4547-ba39-04bd4bead7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 30):\n",
    "#      with open('data/daftar_kata.txt', 'w') as f:\n",
    "#         print(df2['tweet'].str.split(expand=True).stack().value_counts(), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43efbc35-1fe6-4858-9e0e-846aebde89a5",
   "metadata": {},
   "source": [
    "### Pie chart dari data labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf50058c-9d9e-41ae-94dc-8343bc575bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([len(df2[df2.sentimen==\"Positif\"]),  len(df2[df2.sentimen==\"Netral\"]), len(df2[df2.sentimen==\"Negatif\"])])\n",
    "mylabels = ['Positif', 'Netral', 'Negatif']\n",
    "mycolors = ['lightblue', 'lightgreen', 'orange']\n",
    "myexplode = [0, 0.2, 0]\n",
    "\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "plt.pie(y, colors=mycolors, labels = mylabels, explode = myexplode, shadow=True, autopct='%1.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fd4cb2-e264-4a4c-9d44-3aa3c94b32e4",
   "metadata": {},
   "source": [
    "### Wordcloud semua data, positif, netral, dan negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a57c98-aa8a-48ea-a3c6-3a00e0d3bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(\"data/cloud.png\"))\n",
    "\n",
    "def plot_cloud(title, text):\n",
    "    wc = WordCloud(scale=3,max_words=100,font_path=\"data/font/GothamMedium.ttf\",background_color='white',\n",
    "                   mask=mask,contour_color='black',contour_width=1).generate(str(\" \".join(text)))\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(40,30))\n",
    "    # Insert image wordcloud\n",
    "    plt.imshow(wc) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\")\n",
    "    # Add Title\n",
    "    plt.title(title)\n",
    "    # Display image\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8ee3d-47c1-4167-b63c-6389e4cacdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df2['tweet'].astype('U')\n",
    "\n",
    "plot_cloud(\"Semua Data\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a318d7a-07fb-4022-8d34-63906c6da8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pos = df2[df2.sentimen==\"Positif\"].tweet.astype('U')\n",
    "\n",
    "plot_cloud(\"Data Positif\", text_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f7309-107e-4baa-a2aa-448b1a721036",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_net = df2[df2.sentimen==\"Netral\"].tweet.astype('U')\n",
    "\n",
    "plot_cloud(\"Data Netral\", text_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae616896-9f7a-4372-8ed0-d0335e11302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_neg = df2[df2.sentimen==\"Negatif\"].tweet.astype('U')\n",
    "\n",
    "plot_cloud(\"Data Negatif\", text_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de50b5c7-208c-49cd-a9e9-5fcee622d200",
   "metadata": {},
   "source": [
    "## Export data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5488af7-f022-4394-9538-0a424ef0330d",
   "metadata": {},
   "source": [
    "### Ekspor data per kata positif, negatif, atau netral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee768c72-f379-4844-92be-ca46e512cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_positif = df2[df2.sentimen==\"Positif\"]\n",
    "df2_netral = df2[df2.sentimen==\"Netral\"]\n",
    "df2_negatif = df2[df2.sentimen==\"Negatif\"]\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.width', 30):\n",
    "    with open('data/temp/daftar_kata_all_roberta.txt', 'w') as f:\n",
    "        print(df2['tweet'].str.split(expand=True).stack().value_counts(), file=f)\n",
    "    with open('data/temp/daftar_kata_positif_roberta.txt', 'w') as f:\n",
    "        print(df2_positif['tweet'].str.split(expand=True).stack().value_counts(), file=f)\n",
    "    with open('data/temp/daftar_kata_netral_roberta.txt', 'w') as f:\n",
    "        print(df2_netral['tweet'].str.split(expand=True).stack().value_counts(), file=f)\n",
    "    with open('data/temp/daftar_kata_negatif_roberta.txt', 'w') as f:\n",
    "        print(df2_negatif['tweet'].str.split(expand=True).stack().value_counts(), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b295f9-d406-45df-9152-9b16b290b0c9",
   "metadata": {},
   "source": [
    "### Ekspor data labelling untokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade7a0a1-499b-4af3-9909-c2581e6a48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"data/tweets_labelled_roberta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad398151-000d-4bc9-94ba-521d9e005b29",
   "metadata": {},
   "source": [
    "### Ekspor data labelling tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564608f-0357-481b-a8a7-67bf7c810ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "df2['tweet'] = df2['tweet'].apply(word_tokenize_wrapper)\n",
    "df2.to_csv(\"data/tweets_labelled_tokenized_roberta.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('data-mining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c3e6423842ed7db2f96ef7b0b918d43a5807d8b2148664ac76af26d1a8eb93f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
