{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df53ccb-7a72-4c6b-9ff0-413194bb012e",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "Menjadikan kata yang memiliki imbuhan menjadi kata dasar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed4899-66b9-42b7-ad17-a11344426015",
   "metadata": {},
   "source": [
    "## Import module / package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d70969-62b1-41f5-a201-a9856e130499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a7134c-e1ba-4b22-a5a4-dd701e88085a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['jbharga', 'ayam', 'rm', 'tgk', 'telor', 'wya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['diri di atas kaki sendiri', 'serap', 'telur'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['sebab', 'harga', 'telur', 'anjlok', 'versi',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['turun', 'minta', 'masyarakat', 'telur', 'aya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['ternak', 'ayam', 'telur', 'aku', 'rugi', 'ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['harga', 'jual', 'telur', 'ayam', 'solo', 'ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['harga', 'telur', 'anjlok', 'rp', 'kg', 'peri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['ikut', 'main', 'telur', 'bareng', 'voucher',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['telor', 'geprek', 'abah', 'uya', 'selera', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['beli', 'order', 'telur', 'set', 'telur', 'mc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  ['jbharga', 'ayam', 'rm', 'tgk', 'telor', 'wya...\n",
       "1  ['diri di atas kaki sendiri', 'serap', 'telur'...\n",
       "2  ['sebab', 'harga', 'telur', 'anjlok', 'versi',...\n",
       "3  ['turun', 'minta', 'masyarakat', 'telur', 'aya...\n",
       "4  ['ternak', 'ayam', 'telur', 'aku', 'rugi', 'ra...\n",
       "5  ['harga', 'jual', 'telur', 'ayam', 'solo', 'ra...\n",
       "6  ['harga', 'telur', 'anjlok', 'rp', 'kg', 'peri...\n",
       "7  ['ikut', 'main', 'telur', 'bareng', 'voucher',...\n",
       "8  ['telor', 'geprek', 'abah', 'uya', 'selera', '...\n",
       "9  ['beli', 'order', 'telur', 'set', 'telur', 'mc..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"data/tweets_clean.csv\")\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f6eb661-e3fb-4839-a519-54a58b6d4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_detokenize = []\n",
    "\n",
    "def detokenize(text):\n",
    "    text1 = text.replace(']','').replace('[','')\n",
    "    arr = text1.replace('\"','').replace(\"\\'\",\"\").split(\",\")\n",
    "    return(TreebankWordDetokenizer().detokenize(arr))\n",
    "\n",
    "dataset['tweet'] = dataset['tweet'].astype('U').apply(detokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a69d177-3c99-443e-93d9-bd6cb94d2f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/anz007/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       [jbharga, ayam, rm, tgk, telor, wyam, papan, r...\n",
       "1       [diri, di, atas, kaki, sendiri, serap, telur, ...\n",
       "2       [sebab, harga, telur, anjlok, versi, dagang, k...\n",
       "3       [turun, minta, masyarakat, telur, ayam, ppkm, ...\n",
       "4       [ternak, ayam, telur, aku, rugi, ratus, juta, ...\n",
       "                              ...                        \n",
       "4381    [benda, bodoh, dengar, harini, beli, lunch, na...\n",
       "4382    [komoditi, alami, turun, harga, daging, ayam, ...\n",
       "4383    [qiraniayr, harga, telor, turun, harga, minyak...\n",
       "4384    [nak, tolong, niaga, melayu, roti, telur, harg...\n",
       "4385    [rep, kilo, butir, harga, ribu, papan, telur, ...\n",
       "Name: tweet, Length: 4386, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "dataset['tweet'] = dataset['tweet'].apply(word_tokenize_wrapper)\n",
    "dataset['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c72804-ffdc-4a05-acf9-841798aa51fb",
   "metadata": {},
   "source": [
    "Library Sastrawi _(Algoritma Nazief)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a600921-0eab-4c0e-9e6d-a1395c189a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022ea35819b54aa79fb07900a7a2f5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4386 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jbharga, ayam, rm, tgk, telor, wyam, papan, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[diri, di, atas, kaki, sendiri, serap, telur, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[sebab, harga, telur, anjlok, versi, dagang, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[turun, minta, masyarakat, telur, ayam, ppkm, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ternak, ayam, telur, aku, rugi, ratus, juta, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>[benda, bodoh, dengar, harini, beli, lunch, na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>[komoditi, alami, turun, harga, daging, ayam, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>[qiraniayr, harga, telor, turun, harga, minyak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>[nak, tolong, niaga, melayu, roti, telur, harg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>[rep, kilo, butir, harga, ribu, papan, telur, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4386 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet\n",
       "0     [jbharga, ayam, rm, tgk, telor, wyam, papan, r...\n",
       "1     [diri, di, atas, kaki, sendiri, serap, telur, ...\n",
       "2     [sebab, harga, telur, anjlok, versi, dagang, k...\n",
       "3     [turun, minta, masyarakat, telur, ayam, ppkm, ...\n",
       "4     [ternak, ayam, telur, aku, rugi, ratus, juta, ...\n",
       "...                                                 ...\n",
       "4381  [benda, bodoh, dengar, harini, beli, lunch, na...\n",
       "4382  [komoditi, alami, turun, harga, daging, ayam, ...\n",
       "4383  [qiraniayr, harga, telor, turun, harga, minyak...\n",
       "4384  [nak, tolong, niaga, melayu, roti, telur, harg...\n",
       "4385  [rep, kilo, butir, harga, ribu, papan, telur, ...\n",
       "\n",
       "[4386 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "tqdm.pandas()\n",
    "dataset['tweet'] = dataset['tweet'].progress_apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6f2876-dd5d-433b-b122-0ec86468e4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
